"""\nWeb viewer for Telegram Backup.\n\nFastAPI application providing a web interface to browse backed-up messages.\nv3.0: Async database operations with SQLAlchemy.\nv5.0: WebSocket support for real-time updates and notifications.\n"""\n\nimport asyncio\nimport glob\nimport hashlib\nimport json\nimport logging\nimport os\nimport secrets\nimport time\nfrom collections.abc import AsyncGenerator\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\nfrom urllib.parse import quote\nfrom zoneinfo import ZoneInfo\n\nfrom fastapi import Cookie, Depends, FastAPI, HTTPException, Query, Request, WebSocket, WebSocketDisconnect\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import FileResponse, HTMLResponse, JSONResponse, StreamingResponse\nfrom fastapi.staticfiles import StaticFiles\n\nfrom ..config import Config\nfrom ..db import DatabaseAdapter, close_database, get_db_manager, init_database\nfrom ..realtime import RealtimeListener\n\nif TYPE_CHECKING:\n    from .push import PushNotificationManager\n\n# Register MIME types for audio files (required for StaticFiles to serve with correct Content-Type)\nimport mimetypes\n\nmimetypes.add_type("audio/ogg", ".ogg")\nmimetypes.add_type("audio/opus", ".opus")\nmimetypes.add_type("audio/mpeg", ".mp3")\nmimetypes.add_type("audio/wav", ".wav")\nmimetypes.add_type("audio/flac", ".flac")\nmimetypes.add_type("audio/x-m4a", ".m4a")\nmimetypes.add_type("video/mp4", ".mp4")\nmimetypes.add_type("video/webm", ".webm")\nmimetypes.add_type("image/webp", ".webp")\n\n\n# WebSocket Connection Manager for real-time updates\nclass ConnectionManager:\n    \"\"\"Manages WebSocket connections for real-time updates.\"\"\"\n\n    def __init__(self):\n        self.active_connections: dict[WebSocket, set[int]] = {}\n        self._allowed_chats: dict[WebSocket, set[int] | None] = {}\n\n    async def connect(self, websocket: WebSocket, allowed_chat_ids: set[int] | None = None):\n        await websocket.accept()\n        self.active_connections[websocket] = set()\n        self._allowed_chats[websocket] = allowed_chat_ids\n        logger.info(f"WebSocket connected. Total connections: {len(self.active_connections)}")\n\n    def disconnect(self, websocket: WebSocket):\n        self.active_connections.pop(websocket, None)\n        self._allowed_chats.pop(websocket, None)\n        logger.info(f"WebSocket disconnected. Total connections: {len(self.active_connections)}")\n\n    def subscribe(self, websocket: WebSocket, chat_id: int):\n        \"\"\"Subscribe a connection to updates for a specific chat.\"\"\"\n        if websocket in self.active_connections:\n            allowed = self._allowed_chats.get(websocket)\n            if allowed is not None and chat_id not in allowed:\n                return\n            self.active_connections[websocket].add(chat_id)\n\n    def unsubscribe(self, websocket: WebSocket, chat_id: int):\n        \"\"\"Unsubscribe a connection from a specific chat.\"\"\"\n        if websocket in self.active_connections:\n            self.active_connections[websocket].discard(chat_id)\n\n    async def broadcast_to_chat(self, chat_id: int, message: dict):\n        \"\"\"Broadcast a message to all connections subscribed to a chat.\"\"\"\n        disconnected = []\n        for websocket, subscribed_chats in self.active_connections.items():\n            allowed = self._allowed_chats.get(websocket)\n            if allowed is not None and chat_id not in allowed:\n                continue\n            if chat_id in subscribed_chats or not subscribed_chats:\n                try:\n                    await websocket.send_json(message)\n                except Exception as e:\n                    logger.warning(f"Failed to send to websocket: {e}")\n                    disconnected.append(websocket)\n\n        # Clean up disconnected sockets\n        for ws in disconnected:\n            self.disconnect(ws)\n\n    async def broadcast_to_all(self, message: dict):\n        \"\"\"Broadcast a message to all connected clients.\"\"\"\n        disconnected = []\n        for websocket in self.active_connections:\n            try:\n                await websocket.send_json(message)\n            except Exception as e:\n                logger.warning(f"Failed to send to websocket: {e}")\n                disconnected.append(websocket)\n\n        for ws in disconnected:\n            self.disconnect(ws)\n\n\n# Global connection manager\nws_manager = ConnectionManager()\n\n# Configure logging\nlogging.basicConfig(format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialize config\nconfig = Config()\n\n# Global database adapter (initialized on startup)\ndb: DatabaseAdapter | None = None\n\n\nasync def _normalize_display_chat_ids():\n    \"\"\"\n    Normalize DISPLAY_CHAT_IDS to use marked format.\n\n    If a positive ID doesn't exist in DB but -100{id} does, auto-correct it.\n    This handles common user mistakes where they forget the -100 prefix for channels.\n    \"\"\"\n    if not config.display_chat_ids or not db:\n        return\n\n    all_chats = await db.get_all_chats()\n    existing_ids = {c["id"] for c in all_chats}\n\n    normalized = set()\n    for chat_id in config.display_chat_ids:\n        if chat_id in existing_ids:\n            # ID exists as-is\n            normalized.add(chat_id)\n        elif chat_id > 0:\n            # Positive ID not found - try -100 prefix (channel/supergroup format)\n            marked_id = -1000000000000 - chat_id\n            if marked_id in existing_ids:\n                logger.warning(\n                    f"DISPLAY_CHAT_IDS: Auto-correcting {chat_id} \u2192 {marked_id} "\n                    f"(use marked format for channels/supergroups)"\n                )\n                normalized.add(marked_id)\n            else:\n                logger.warning(f"DISPLAY_CHAT_IDS: Chat ID {chat_id} not found in database")\n                normalized.add(chat_id)  # Keep original, might be backed up later\n        else:\n            # Negative ID not found\n            logger.warning(f"DISPLAY_CHAT_IDS: Chat ID {chat_id} not found in database")\n            normalized.add(chat_id)\n\n    config.display_chat_ids = normalized\n\n\n# Background tasks\nstats_task: asyncio.Task | None = None\n_session_cleanup_task: asyncio.Task | None = None\n\n# Real-time listener (PostgreSQL LISTEN/NOTIFY)\nrealtime_listener: RealtimeListener | None = None\n\n# Push notification manager (Web Push API)\npush_manager: PushNotificationManager | None = None\n\n\nasync def handle_realtime_notification(payload: dict):\n    \"\"\"Handle real-time notifications and broadcast to WebSocket clients + push notifications.\"\"\"\n    notification_type = payload.get("type")\n    chat_id = payload.get("chat_id")\n    data = payload.get("data", {})\n\n    # Check if this chat is allowed (respects DISPLAY_CHAT_IDS restriction)\n    if config.display_chat_ids and chat_id not in config.display_chat_ids:\n        # This viewer is restricted to specific chats, ignore notifications for other chats\n        return\n\n    if notification_type == "new_message":\n        await ws_manager.broadcast_to_chat(chat_id, {"type": "new_message", "message": data.get("message")})\n\n        # Send Web Push notification for new messages\n        if push_manager and push_manager.is_enabled:\n            message = data.get("message", {})\n            # Get chat info for the notification\n            chat = await db.get_chat_by_id(chat_id) if db else None\n            chat_title = chat.get("title", "Telegram") if chat else "Telegram"\n\n            sender_name = ""\n            if message.get("sender_id"):\n                sender = await db.get_user_by_id(message.get("sender_id")) if db else None\n                if sender:\n                    sender_name = sender.get("first_name", "") or sender.get("username", "")\n\n            await push_manager.notify_new_message(\n                chat_id=chat_id,\n                chat_title=chat_title,\n                sender_name=sender_name,\n                message_text=message.get("text", "") or "[Media]",\n                message_id=message.get("id", 0),\n            )\n\n    elif notification_type == "edit":\n        await ws_manager.broadcast_to_chat(\n            chat_id, {"type": "edit", "message_id": data.get("message_id"), "new_text": data.get("new_text")}\n        )\n    elif notification_type == "delete":\n        await ws_manager.broadcast_to_chat(chat_id, {"type": "delete", "message_id": data.get("message_id")})\n\n\nasync def session_cleanup_task():\n    \"\"\"Periodically evict expired sessions and stale rate limit entries.\"\"\"\n    while True:\n        try:\n            await asyncio.sleep(_SESSION_CLEANUP_INTERVAL)\n            now = time.time()\n            expired = [k for k, v in _sessions.items() if now - v.created_at > AUTH_SESSION_SECONDS]\n            for k in expired:\n                _sessions.pop(k, None)\n            if expired:\n                logger.info(f"Cleaned up {len(expired)} expired sessions")\n            stale_ips = [ip for ip, ts in _login_attempts.items() if all(now - t > _LOGIN_RATE_WINDOW for t in ts)]\n            for ip in stale_ips:\n                _login_attempts.pop(ip, None)\n        except asyncio.CancelledError:\n            break\n        except Exception as e:\n            logger.error(f"Session cleanup error: {e}")\n\n\nasync def stats_calculation_scheduler():\n    \"\"\"Background task that runs stats calculation daily at configured hour.\"\"\"\n    while True:\n        try:\n            # Get current time in configured timezone\n            tz = ZoneInfo(config.viewer_timezone)\n            now = datetime.now(tz)\n\n            # Calculate next run time (configured hour, e.g., 3am)\n            target_hour = config.stats_calculation_hour\n            next_run = now.replace(hour=target_hour, minute=0, second=0, microsecond=0)\n\n            # If we've passed the target time today, schedule for tomorrow\n            if now.hour >= target_hour:\n                next_run = next_run.replace(day=now.day + 1)\n\n            # Wait until next run\n            wait_seconds = (next_run - now).total_seconds()\n            logger.info(\n                f"Stats calculation scheduled for {next_run.strftime('%Y-%m-%d %H:%M')} ({wait_seconds / 3600:.1f}h from now)"\n            )\n            await asyncio.sleep(wait_seconds)\n\n            # Run stats calculation\n            logger.info("Running scheduled stats calculation...")\n            await db.calculate_and_store_statistics()\n            logger.info("Stats calculation completed")\n\n        except asyncio.CancelledError:\n            logger.info("Stats calculation scheduler cancelled")\n            break\n        except Exception as e:\n            logger.error(f"Error in stats calculation scheduler: {e}")\n            # Wait an hour before retrying on error\n            await asyncio.sleep(3600)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI) -> AsyncGenerator[None]:\n    \"\"\"Manage application lifecycle - initialize and cleanup database.\"\"\"\n    global db, stats_task, _session_cleanup_task\n    logger.info("Initializing database connection...")\n    db_manager = await init_database()\n    db = DatabaseAdapter(db_manager)\n    logger.info("Database connection established")\n\n    # Normalize display chat IDs (auto-correct missing -100 prefix)\n    await _normalize_display_chat_ids()\n\n    # Check if stats have ever been calculated, if not, run initial calculation\n    stats_calculated_at = await db.get_metadata("stats_calculated_at")\n    if not stats_calculated_at:\n        logger.info("No cached stats found, running initial calculation...")\n        try:\n            await db.calculate_and_store_statistics()\n        except Exception as e:\n            logger.warning(f"Initial stats calculation failed: {e}")\n\n    # Start background tasks\n    stats_task = asyncio.create_task(stats_calculation_scheduler())\n    _session_cleanup_task = asyncio.create_task(session_cleanup_task())\n    logger.info(\n        f"Stats calculation scheduler started (runs daily at {config.stats_calculation_hour}:00 {config.viewer_timezone})"\n    )\n\n    # Start real-time listener (auto-detects PostgreSQL vs SQLite)\n    global realtime_listener\n    db_manager_instance = await get_db_manager()\n    realtime_listener = RealtimeListener(db_manager_instance, callback=handle_realtime_notification)\n    await realtime_listener.init()\n    await realtime_listener.start()\n    logger.info("Real-time listener started (auto-detected database type)")\n\n    # Initialize Web Push notifications (if enabled)\n    global push_manager\n    if config.push_notifications == "full":\n        from .push import PushNotificationManager\n\n        push_manager = PushNotificationManager(db, config)\n        push_enabled = await push_manager.initialize()\n        if push_enabled:\n            logger.info("Web Push notifications enabled (PUSH_NOTIFICATIONS=full)")\n        else:\n            logger.warning("Web Push notifications failed to initialize")\n    else:\n        logger.info(f"Push notifications mode: {config.push_notifications}")\n\n    yield\n\n    # Cleanup\n    if realtime_listener:\n        await realtime_listener.stop()\n\n    for task in [stats_task, _session_cleanup_task]:\n        if task:\n            task.cancel()\n            try:\n                await task\n            except asyncio.CancelledError:\n                pass\n\n    logger.info("Closing database connection...")\n    await close_database()\n    logger.info("Database connection closed")\n\n\napp = FastAPI(title="Telegram Archive", lifespan=lifespan)\n\n# Enable CORS\n# CORS_ORIGINS env var: comma-separated list of allowed origins (default: \"*\")\n# When using \"*\", credentials are disabled for security (browser requirement)\n_cors_origins_raw = os.getenv("CORS_ORIGINS", "*").strip()\n_cors_origins = [o.strip() for o in _cors_origins_raw.split(",") if o.strip()]\n_cors_allow_credentials = _cors_origins != ["*"]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=_cors_origins,\n    allow_credentials=_cors_allow_credentials,\n    allow_methods=["GET", "POST", "PUT", "DELETE"],\n    allow_headers=["*"],\n)\n\n\n@app.middleware("http")\nasync def add_security_headers(request: Request, call_next):\n    \"\"\"Add security headers to all responses.\"\"\"\n    response = await call_next(request)\n    response.headers["X-Content-Type-Options"] = "nosniff"\n    response.headers["X-Frame-Options"] = "SAMEORIGIN"\n    response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"\n    response.headers["Content-Security-Policy"] = (\n        "default-src 'self'; "\n        "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.tailwindcss.com https://unpkg.com https://cdnjs.cloudflare.com https://cdn.jsdelivr.net; "\n        "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com https://cdnjs.cloudflare.com https://cdn.jsdelivr.net; "\n        "img-src 'self' data: blob:; "\n        "media-src 'self' blob:; "\n        "connect-src 'self' ws: wss:; "\n        "font-src 'self' https://fonts.gstatic.com https://cdnjs.cloudflare.com"\n    )\n    return response\n\n\n# ============================================================================\n# Multi-User Authentication (v7.0.0)\n# ============================================================================\n\nVIEWER_USERNAME = os.getenv("VIEWER_USERNAME", "").strip()\nVIEWER_PASSWORD = os.getenv("VIEWER_PASSWORD", "").strip()\nAUTH_ENABLED = bool(VIEWER_USERNAME and VIEWER_PASSWORD)\nAUTH_COOKIE_NAME = "viewer_auth"\n\nAUTH_SESSION_DAYS = int(os.getenv("AUTH_SESSION_DAYS", "30"))\nAUTH_SESSION_SECONDS = AUTH_SESSION_DAYS * 24 * 60 * 60\n_MAX_SESSIONS_PER_USER = 10\n_SESSION_CLEANUP_INTERVAL = 900  # 15 minutes\n_LOGIN_RATE_LIMIT = 15  # max attempts\n_LOGIN_RATE_WINDOW = 300  # per 5 minutes\n\nif AUTH_ENABLED:\n    logger.info(f"Viewer authentication is ENABLED (Master: {VIEWER_USERNAME}, Session: {AUTH_SESSION_DAYS} days)")\nelse:\n    logger.info("Viewer authentication is DISABLED (no VIEWER_USERNAME / VIEWER_PASSWORD set)")\n\n\n@dataclass\nclass UserContext:\n    username: str\n    role: str  # \"master\" or \"viewer\"\n    allowed_chat_ids: set[int] | None = None  # None = all chats\n\n\n@dataclass\nclass SessionData:\n    username: str\n    role: str\n    allowed_chat_ids: set[int] | None = None\n    created_at: float = field(default_factory=time.time)\n    last_accessed: float = field(default_factory=time.time)\n\n\n_sessions: dict[str, SessionData] = {}\n_login_attempts: dict[str, list[float]] = {}  # ip -> list of timestamps\n\n\ndef _hash_password(password: str, salt: str) -> str:\n    return hashlib.pbkdf2_hmac("sha256", password.encode(), salt.encode(), 600_000).hex()\n\n\ndef _verify_password(password: str, salt: str, password_hash: str) -> bool:\n    return secrets.compare_digest(_hash_password(password, salt), password_hash)\n\n\ndef _check_rate_limit(ip: str) -> bool:\n    \"\"\"Returns True if the request is within rate limits.\"\"\"\n    now = time.time()\n    attempts = _login_attempts.get(ip, [])\n    attempts = [t for t in attempts if now - t < _LOGIN_RATE_WINDOW]\n    _login_attempts[ip] = attempts\n    return len(attempts) < _LOGIN_RATE_LIMIT\n\n\ndef _record_login_attempt(ip: str) -> None:\n    _login_attempts.setdefault(ip, []).append(time.time())\n\n\ndef _create_session(username: str, role: str, allowed_chat_ids: set[int] | None = None) -> str:\n    \"\"\"Create a new session, evicting oldest if user exceeds max sessions.\"\"\"\n    user_sessions = [(k, v) for k, v in _sessions.items() if v.username == username]\n    if len(user_sessions) >= _MAX_SESSIONS_PER_USER:\n        user_sessions.sort(key=lambda x: x[1].created_at)\n        for token, _ in user_sessions[: len(user_sessions) - _MAX_SESSIONS_PER_USER + 1]:\n            _sessions.pop(token, None)\n\n    token = secrets.token_urlsafe(32)\n    _sessions[token] = SessionData(username=username, role=role, allowed_chat_ids=allowed_chat_ids)\n    return token\n\n\ndef _invalidate_user_sessions(username: str) -> None:\n    \"\"\"Remove all sessions for a given username.\"\"\"\n    to_remove = [k for k, v in _sessions.items() if v.username == username]\n    for k in to_remove:\n        _sessions.pop(k, None)\n\n\ndef _get_secure_cookies(request: Request) -> bool:\n    secure_env = os.getenv("SECURE_COOKIES", "").strip().lower()\n    if secure_env == "true":\n        return True\n    if secure_env == "false":\n        return False\n    forwarded_proto = request.headers.get("x-forwarded-proto", "")\n    return forwarded_proto == "https" or str(request.url.scheme) == "https"\n\n\ndef require_auth(auth_cookie: str | None = Cookie(default=None, alias=AUTH_COOKIE_NAME)) -> UserContext:\n    \"\"\"Dependency that enforces session-based auth. Returns UserContext.\"\"\"\n    if not AUTH_ENABLED:\n        return UserContext(username="anonymous", role="master", allowed_chat_ids=None)\n\n    if not auth_cookie:\n        raise HTTPException(status_code=401, detail="Unauthorized")\n\n    session = _sessions.get(auth_cookie)\n    if not session:\n        raise HTTPException(status_code=401, detail="Unauthorized")\n\n    if time.time() - session.created_at > AUTH_SESSION_SECONDS:\n        _sessions.pop(auth_cookie, None)\n        raise HTTPException(status_code=401, detail="Session expired")\n\n    session.last_accessed = time.time()\n    return UserContext(\n        username=session.username,\n        role=session.role,\n        allowed_chat_ids=session.allowed_chat_ids,\n    )\n\n\ndef require_master(user: UserContext = Depends(require_auth)) -> UserContext:\n    \"\"\"Dependency that requires master role.\"\"\"\n    if user.role != "master":\n        raise HTTPException(status_code=403, detail="Admin access required")\n    return user\n\n\ndef get_user_chat_ids(user: UserContext) -> set[int] | None:\n    \"\"\"Get the effective chat IDs a user can access.\n\n    Returns None if the user can see all chats (no restriction).\n    \"\"\"\n    master_filter = config.display_chat_ids or None  # empty set -> None\n\n    if user.role == "master":\n        return master_filter\n\n    # Viewer: use their allowed_chat_ids, intersected with master filter\n    if user.allowed_chat_ids is None:\n        return master_filter\n    if master_filter is None:\n        return user.allowed_chat_ids\n    return user.allowed_chat_ids & master_filter\n\n\n# Setup paths\ntemplates_dir = Path(__file__).parent / "templates"\nstatic_dir = Path(__file__).parent / "static"\n\n\n@app.get("/sw.js")\nasync def serve_service_worker():\n    \"\"\"\n    Serve the service worker from root path with proper headers.\n\n    The Service-Worker-Allowed header allows the SW to have scope '/'\n    even though the file is served from /static/sw.js.\n    \"\"\"\n    sw_path = static_dir / "sw.js"\n    if not sw_path.exists():\n        raise HTTPException(status_code=404, detail="Service worker not found")\n\n    return FileResponse(sw_path, media_type="application/javascript", headers={"Service-Worker-Allowed": "/"})\n\n\n# Mount static directory (no auth needed for CSS/JS/icons)\nif static_dir.exists():\n    app.mount("/static", StaticFiles(directory=static_dir), name="static")\n\n# Media is served via authenticated endpoint below (not StaticFiles)\n_media_root = Path(config.media_path).resolve() if os.path.exists(config.media_path) else None\n\n\n@app.get("/media/{path:path}")\nasync def serve_media(path: str, user: UserContext = Depends(require_auth)):\n    \"\"\"Serve media files with authentication and path traversal protection.\"\"\"\n    if not _media_root:\n        raise HTTPException(status_code=404, detail="Media directory not configured")\n\n    resolved = (_media_root / path).resolve()\n    if not resolved.is_relative_to(_media_root):\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None:\n        parts = path.split("/")\n        if len(parts) >= 2 and parts[0] != "avatars":\n            try:\n                media_chat_id = int(parts[0])\n                if media_chat_id not in user_chat_ids:\n                    raise HTTPException(status_code=403, detail="Access denied")\n            except ValueError:\n                pass\n\n    if not resolved.is_file():\n        raise HTTPException(status_code=404, detail="File not found")\n\n    return FileResponse(resolved)\n\n\n@app.get("/", response_class=HTMLResponse)\nasync def read_root():\n    \"\"\"Serve the main application page.\"\"\"\n    return FileResponse(\n        templates_dir / "index.html",\n        headers={"Cache-Control": "no-cache, must-revalidate"},\n    )\n\n\n@app.get("/api/auth/check")\nasync def check_auth(auth_cookie: str | None = Cookie(default=None, alias=AUTH_COOKIE_NAME)):\n    \"\"\"Check current authentication status. Returns role and username if authenticated.\"\"\"\n    if not AUTH_ENABLED:\n        return {"authenticated": True, "auth_required": False, "role": "master", "username": "anonymous"}\n\n    if not auth_cookie:\n        return {"authenticated": False, "auth_required": True}\n\n    session = _sessions.get(auth_cookie)\n    if not session or time.time() - session.created_at > AUTH_SESSION_SECONDS:\n        return {"authenticated": False, "auth_required": True}\n\n    return {\n        "authenticated": True,\n        "auth_required": True,\n        "role": session.role,\n        "username": session.username,\n    }\n\n\n@app.post("/api/login")\nasync def login(request: Request):\n    \"\"\"Authenticate user (master via env vars or viewer via DB accounts).\"\"\"\n    if not AUTH_ENABLED:\n        return JSONResponse({"success": True, "message": "Auth disabled"})\n\n    direct_ip = request.client.host if request.client else "unknown"\n    _trusted = direct_ip.startswith(("172.", "10.", "192.168.", "127.")) or direct_ip in ("::1", "localhost")\n    if _trusted:\n        client_ip = (\n            request.headers.get("x-forwarded-for", "").split(",")[0].strip()\n            or request.headers.get("x-real-ip", "")\n            or direct_ip\n        )\n    else:\n        client_ip = direct_ip\n\n    if not _check_rate_limit(client_ip):\n        raise HTTPException(status_code=429, detail="Too many login attempts. Try again later.")\n\n    try:\n        data = await request.json()\n        username = data.get("username", "").strip()\n        password = data.get("password", "").strip()\n    except Exception:\n        raise HTTPException(status_code=400, detail="Invalid request")\n\n    if not username or not password:\n        raise HTTPException(status_code=400, detail="Username and password required")\n\n    _record_login_attempt(client_ip)\n    user_agent = request.headers.get("user-agent", "")[:500]\n\n    # 1. Check DB viewer accounts first\n    if db:\n        viewer = await db.get_viewer_by_username(username)\n        if viewer and viewer["is_active"]:\n            if _verify_password(password, viewer["salt"], viewer["password_hash"]):\n                allowed = None\n                if viewer["allowed_chat_ids"]:\n                    try:\n                        allowed = set(json.loads(viewer["allowed_chat_ids"]))\n                    except (json.JSONDecodeError, TypeError):\n                        allowed = None\n\n                token = _create_session(username, "viewer", allowed)\n                response = JSONResponse({"success": True, "role": "viewer", "username": username})\n                response.set_cookie(\n                    key=AUTH_COOKIE_NAME,\n                    value=token,\n                    httponly=True,\n                    secure=_get_secure_cookies(request),\n                    samesite="lax",\n                    max_age=AUTH_SESSION_SECONDS,\n                )\n\n                if db:\n                    await db.create_audit_log(\n                        username=username,\n                        role="viewer",\n                        action="login_success",\n                        endpoint="/api/login",\n                        ip_address=client_ip,\n                        user_agent=user_agent,\n                    )\n                return response\n\n    # 2. Fall back to master env var credentials\n    if secrets.compare_digest(username, VIEWER_USERNAME) and secrets.compare_digest(password, VIEWER_PASSWORD):\n        token = _create_session(username, "master", None)\n        response = JSONResponse({"success": True, "role": "master", "username": username})\n        response.set_cookie(\n            key=AUTH_COOKIE_NAME,\n            value=token,\n            httponly=True,\n            secure=_get_secure_cookies(request),\n            samesite="lax",\n            max_age=AUTH_SESSION_SECONDS,\n        )\n\n        if db:\n            await db.create_audit_log(\n                username=username,\n                role="master",\n                action="login_success",\n                endpoint="/api/login",\n                ip_address=client_ip,\n                user_agent=user_agent,\n            )\n        return response\n\n    # Failed login\n    if db:\n        await db.create_audit_log(\n            username=username or "(empty)",\n            role="unknown",\n            action="login_failed",\n            endpoint="/api/login",\n            ip_address=client_ip,\n            user_agent=user_agent,\n        )\n    raise HTTPException(status_code=401, detail="Invalid credentials")\n\n\n@app.post("/api/logout")\nasync def logout(\n    request: Request,\n    auth_cookie: str | None = Cookie(default=None, alias=AUTH_COOKIE_NAME),\n):\n    \"\"\"Invalidate current session and clear cookie.\"\"\"\n    if auth_cookie and auth_cookie in _sessions:\n        session = _sessions.pop(auth_cookie)\n        if db:\n            await db.create_audit_log(\n                username=session.username,\n                role=session.role,\n                action="logout",\n                endpoint="/api/logout",\n                ip_address=request.client.host if request.client else None,\n            )\n\n    response = JSONResponse({"success": True})\n    response.delete_cookie(AUTH_COOKIE_NAME)\n    return response\n\n\ndef _find_avatar_path(chat_id: int, chat_type: str) -> str | None:\n    \"\"\"Find avatar file path for a chat.\n\n    Avatar files are stored as: {chat_id}_{photo_id}.jpg\n    For groups/channels, chat_id is negative (marked ID format).\n    \"\"\"\n    # Determine folder: 'chats' for groups/channels, 'users' for private\n    avatar_folder = "users" if chat_type == "private" else "chats"\n    avatar_dir = os.path.join(config.media_path, "avatars", avatar_folder)\n\n    if not os.path.exists(avatar_dir):\n        return None\n\n    # Look for avatar file matching chat_id\n    pattern = os.path.join(avatar_dir, f"{chat_id}_*.jpg")\n    matches = glob.glob(pattern)\n\n    # Legacy fallback: files saved without photo_id suffix\n    legacy_path = os.path.join(avatar_dir, f"{chat_id}.jpg")\n    if os.path.exists(legacy_path):\n        matches.append(legacy_path)\n\n    if matches:\n        # Return the most recently modified avatar (newest profile photo)\n        newest_avatar = max(matches, key=os.path.getmtime)\n        avatar_file = os.path.basename(newest_avatar)\n        return f"avatars/{avatar_folder}/{avatar_file}"\n\n    return None\n\n\n# Cache avatar paths to avoid repeated filesystem lookups\n_avatar_cache: dict[int, str | None] = {}\n_avatar_cache_time: datetime | None = None\nAVATAR_CACHE_TTL_SECONDS = 300  # 5 minutes\n\n\ndef _get_cached_avatar_path(chat_id: int, chat_type: str) -> str | None:\n    \"\"\"Get avatar path with caching.\"\"\"\n    global _avatar_cache, _avatar_cache_time\n\n    # Invalidate cache if too old\n    if _avatar_cache_time and (datetime.utcnow() - _avatar_cache_time).total_seconds() > AVATAR_CACHE_TTL_SECONDS:\n        _avatar_cache.clear()\n        _avatar_cache_time = None\n\n    # Check cache\n    if chat_id in _avatar_cache:\n        return _avatar_cache[chat_id]\n\n    # Lookup and cache\n    avatar_path = _find_avatar_path(chat_id, chat_type)\n    _avatar_cache[chat_id] = avatar_path\n    if _avatar_cache_time is None:\n        _avatar_cache_time = datetime.utcnow()\n\n    return avatar_path\n\n\n@app.get("/api/chats")\nasync def get_chats(\n    user: UserContext = Depends(require_auth),\n    limit: int = Query(50, ge=1, le=1000, description="Number of chats to return"),\n    offset: int = Query(0, ge=0, description="Offset for pagination"),\n    search: str = Query(None, description="Search query for chat names/usernames"),\n    archived: bool | None = Query(None, description="Filter by archived status"),\n    folder_id: int | None = Query(None, description="Filter by folder ID"),\n):\n    \"\"\"Get chats with metadata, paginated. Returns most recent chats first.\n\n    If 'search' is provided, returns all chats matching the search query (up to limit).\n    Search is case-insensitive and matches title, first_name, last_name, or username.\n\n    v6.2.0: Added archived and folder_id filters.\n    \"\"\"\n    try:\n        user_chat_ids = get_user_chat_ids(user)\n        # If user has chat restrictions, we need to load all matching chats\n        # Otherwise, use pagination\n        if user_chat_ids is not None:\n            chats = await db.get_all_chats(search=search, archived=archived, folder_id=folder_id)\n            chats = [c for c in chats if c["id"] in user_chat_ids]\n            total = len(chats)\n            # Apply pagination after filtering\n            chats = chats[offset : offset + limit]\n        else:\n            chats = await db.get_all_chats(\n                limit=limit, offset=offset, search=search, archived=archived, folder_id=folder_id\n            )\n            total = await db.get_chat_count(search=search, archived=archived, folder_id=folder_id)\n\n        # Add avatar URLs using cache\n        for chat in chats:\n            try:\n                avatar_path = _get_cached_avatar_path(chat["id"], chat.get("type", "private"))\n                if avatar_path:\n                    chat["avatar_url"] = f"/media/{avatar_path}"\n                else:\n                    chat["avatar_url"] = None\n            except Exception as e:\n                logger.error(f"Error finding avatar for chat {chat.get('id')}: {e}")\n                chat["avatar_url"] = None\n\n        return {\n            "chats": chats,\n            "total": total,\n            "limit": limit,\n            "offset": offset,\n            "has_more": offset + len(chats) < total,\n        }\n    except Exception as e:\n        logger.error(f"Error fetching chats: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/chats/{chat_id}/messages")\nasync def get_messages(\n    chat_id: int,\n    user: UserContext = Depends(require_auth),\n    limit: int = 50,\n    offset: int = 0,\n    search: str | None = None,\n    before_date: str | None = None,\n    before_id: int | None = None,\n    topic_id: int | None = None,\n):\n    \"\"\"\n    Get messages for a specific chat with user and media info.\n\n    Supports two pagination modes:\n    - Offset-based: ?offset=100 (slower for large offsets)\n    - Cursor-based: ?before_date=2026-01-15T12:00:00&before_id=12345 (O(1) performance)\n\n    v6.2.0: Added topic_id filter for forum topic messages.\n\n    Cursor-based pagination is preferred for infinite scroll.\n    \"\"\"\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None and chat_id not in user_chat_ids:\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    # Parse before_date if provided\n    parsed_before_date = None\n    if before_date:\n        try:\n            parsed_before_date = datetime.fromisoformat(before_date.replace("Z", "+00:00"))\n            # Strip timezone for DB compatibility\n            if parsed_before_date.tzinfo:\n                parsed_before_date = parsed_before_date.replace(tzinfo=None)\n        except ValueError:\n            raise HTTPException(status_code=400, detail="Invalid before_date format. Use ISO 8601.")\n\n    try:\n        messages = await db.get_messages_paginated(\n            chat_id=chat_id,\n            limit=limit,\n            offset=offset,\n            search=search,\n            before_date=parsed_before_date,\n            before_id=before_id,\n            topic_id=topic_id,\n        )\n        return messages\n    except Exception as e:\n        logger.error(f"Error fetching messages: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/chats/{chat_id}/pinned")\nasync def get_pinned_messages(chat_id: int, user: UserContext = Depends(require_auth)):\n    \"\"\"Get all pinned messages for a chat, ordered by date descending (newest first).\"\"\"\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None and chat_id not in user_chat_ids:\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    try:\n        pinned_messages = await db.get_pinned_messages(chat_id)\n        return pinned_messages  # Returns empty list if no pinned messages\n    except Exception as e:\n        logger.error(f"Error fetching pinned messages: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/folders")\nasync def get_folders(user: UserContext = Depends(require_auth)):\n    \"\"\"Get all chat folders with their chat counts.\n\n    v6.2.0: Returns user-created Telegram folders (dialog filters).\n    \"\"\"\n    try:\n        folders = await db.get_all_folders()\n        return {"folders": folders}\n    except Exception as e:\n        logger.error(f"Error fetching folders: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/chats/{chat_id}/topics")\nasync def get_chat_topics(chat_id: int, user: UserContext = Depends(require_auth)):\n    \"\"\"Get forum topics for a chat.\n\n    v6.2.0: Returns topic list with message counts for forum-enabled chats.\n    \"\"\"\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None and chat_id not in user_chat_ids:\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    try:\n        topics = await db.get_forum_topics(chat_id)\n        return {"topics": topics}\n    except Exception as e:\n        logger.error(f"Error fetching topics: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/archived/count")\nasync def get_archived_count(user: UserContext = Depends(require_auth)):\n    \"\"\"Get the number of archived chats.\n\n    v6.2.0: Used by the viewer to display the archived section badge.\n    Respects DISPLAY_CHAT_IDS so restricted viewers only see relevant archived chats.\n    \"\"\"\n    try:\n        user_chat_ids = get_user_chat_ids(user)\n        if user_chat_ids is not None:\n            all_archived = await db.get_all_chats(archived=True)\n            count = sum(1 for c in all_archived if c["id"] in user_chat_ids)\n        else:\n            count = await db.get_archived_chat_count()\n        return {"count": count}\n    except Exception as e:\n        logger.error(f"Error fetching archived count: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/stats")\nasync def get_stats(user: UserContext = Depends(require_auth)):\n    \"\"\"Get cached backup statistics (fast, calculated daily).\"\"\"\n    try:\n        stats = await db.get_cached_statistics()\n        stats["timezone"] = config.viewer_timezone\n        stats["stats_calculation_hour"] = config.stats_calculation_hour\n        stats["show_stats"] = config.show_stats  # Whether to show stats UI\n\n        # Check if real-time listener is active (written by backup container)\n        listener_active_since = await db.get_metadata("listener_active_since")\n        stats["listener_active"] = bool(listener_active_since)\n        stats["listener_active_since"] = listener_active_since if listener_active_since else None\n\n        # Notifications config\n        stats["push_notifications"] = config.push_notifications  # off, basic, full\n        stats["push_enabled"] = push_manager is not None and push_manager.is_enabled\n\n        # Notifications enabled if ENABLE_NOTIFICATIONS=true OR PUSH_NOTIFICATIONS is basic/full\n        stats["enable_notifications"] = config.enable_notifications or config.push_notifications in ("basic", "full")\n\n        return stats\n    except Exception as e:\n        logger.error(f"Error fetching stats: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.post("/api/stats/refresh")\nasync def refresh_stats(user: UserContext = Depends(require_master)):\n    \"\"\"Manually trigger stats recalculation (expensive, use sparingly).\"\"\"\n    try:\n        stats = await db.calculate_and_store_statistics()\n        stats["timezone"] = config.viewer_timezone\n        return stats\n    except Exception as e:\n        logger.error(f"Error calculating stats: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n# ============================================================================\n# Web Push Notification Endpoints\n# ============================================================================\n\n\n@app.get("/api/push/config")\nasync def get_push_config():\n    \"\"\"\n    Get push notification configuration.\n\n    Returns the push notification mode and VAPID public key if available.\n    This endpoint is public (no auth) so clients can check before subscribing.\n    \"\"\"\n    result = {\n        "mode": config.push_notifications,\n        "enabled": config.push_notifications == "full" and push_manager is not None and push_manager.is_enabled,\n        "vapid_public_key": None,\n    }\n\n    if push_manager and push_manager.is_enabled:\n        result["vapid_public_key"] = push_manager.public_key\n\n    return result\n\n\n@app.post("/api/push/subscribe")\nasync def push_subscribe(request: Request, user: UserContext = Depends(require_auth)):\n    \"\"\"\n    Subscribe to push notifications.\n\n    Body should contain:\n    - endpoint: Push service URL\n    - keys.p256dh: Client public key (base64)\n    - keys.auth: Auth secret (base64)\n    - chat_id: Optional chat ID for chat-specific subscriptions\n    \"\"\"\n    if not push_manager or not push_manager.is_enabled:\n        raise HTTPException(status_code=400, detail="Push notifications not enabled. Set PUSH_NOTIFICATIONS=full")\n\n    try:\n        data = await request.json()\n\n        endpoint = data.get("endpoint")\n        keys = data.get("keys", {})\n        p256dh = keys.get("p256dh")\n        auth = keys.get("auth")\n        chat_id = data.get("chat_id")\n\n        if not endpoint or not p256dh or not auth:\n            raise HTTPException(status_code=400, detail="Missing required subscription data")\n\n        if chat_id:\n            user_chat_ids = get_user_chat_ids(user)\n            if user_chat_ids is not None and chat_id not in user_chat_ids:\n                raise HTTPException(status_code=403, detail="Access denied to this chat")\n\n        user_agent = request.headers.get("user-agent", "")[:500]\n\n        success = await push_manager.subscribe(\n            endpoint=endpoint, p256dh=p256dh, auth=auth, chat_id=chat_id, user_agent=user_agent\n        )\n\n        if success:\n            return {"status": "subscribed", "chat_id": chat_id}\n        else:\n            raise HTTPException(status_code=500, detail="Failed to store subscription")\n\n    except json.JSONDecodeError:\n        raise HTTPException(status_code=400, detail="Invalid JSON")\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f"Push subscribe error: {e}")\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.post("/api/push/unsubscribe")\nasync def push_unsubscribe(request: Request, user: UserContext = Depends(require_auth)):\n    \"\"\"\n    Unsubscribe from push notifications.\n\n    Body should contain:\n    - endpoint: Push service URL to unsubscribe\n    \"\"\"\n    if not push_manager:\n        raise HTTPException(status_code=400, detail="Push notifications not enabled")\n\n    try:\n        data = await request.json()\n        endpoint = data.get("endpoint")\n\n        if not endpoint:\n            raise HTTPException(status_code=400, detail="Missing endpoint")\n\n        success = await push_manager.unsubscribe(endpoint)\n        return {"status": "unsubscribed" if success else "not_found"}\n\n    except json.JSONDecodeError:\n        raise HTTPException(status_code=400, detail="Invalid JSON")\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f"Push unsubscribe error: {e}")\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.post("/internal/push")\nasync def internal_push(request: Request):\n    \"\"\"\n    Internal endpoint for SQLite real-time push notifications.\n\n    The backup/listener container POSTs to this endpoint when using SQLite,\n    and this broadcasts to connected WebSocket clients.\n\n    For PostgreSQL, use LISTEN/NOTIFY instead (auto-detected).\n\n    Access is restricted to private/loopback IPs and Docker internal networks.\n    \"\"\"\n    client_host = request.client.host if request.client else None\n\n    allowed = False\n    if client_host and (\n        client_host in ("127.0.0.1", "localhost", "::1")\n        or client_host.startswith(("172.", "10.", "192.168."))\n    ):\n        allowed = True\n\n    if not allowed:\n        logger.warning(f"Rejected /internal/push from non-private IP: {client_host}")\n        raise HTTPException(status_code=403, detail="Forbidden")\n\n    try:\n        payload = await request.json()\n        if realtime_listener:\n            await realtime_listener.handle_http_push(payload)\n        return {"status": "ok"}\n    except Exception as e:\n        logger.warning(f"Error handling internal push: {e}")\n        return {"status": "error", "detail": "Internal push processing failed"}\n\n\n@app.get("/api/chats/{chat_id}/stats")\nasync def get_chat_stats(chat_id: int, user: UserContext = Depends(require_auth)):\n    \"\"\"Get statistics for a specific chat (message count, media files, size).\"\"\"\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None and chat_id not in user_chat_ids:\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    try:\n        stats = await db.get_chat_stats(chat_id)\n        return stats\n    except Exception as e:\n        logger.error(f"Error getting chat stats: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/chats/{chat_id}/messages/by-date")\nasync def get_message_by_date(\n    chat_id: int,\n    user: UserContext = Depends(require_auth),\n    date: str = Query(..., description="Date in YYYY-MM-DD format"),\n    timezone: str = Query(None, description="Timezone for date interpretation (e.g., 'Europe/Madrid')"),\n):\n    \"\"\"\n    Find the first message on or after a specific date for navigation.\n    Used by the date picker to jump to a specific date.\n    \"\"\"\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None and chat_id not in user_chat_ids:\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    try:\n        # Use provided timezone, fall back to config, then UTC\n        tz_str = timezone or config.viewer_timezone or "UTC"\n        try:\n            user_tz = ZoneInfo(tz_str)\n        except Exception:\n            logger.warning(f"Invalid timezone '{tz_str}', falling back to UTC")\n            user_tz = ZoneInfo("UTC")\n\n        # Parse date string (YYYY-MM-DD) as a date in the user's timezone\n        naive_date = datetime.strptime(date, "%Y-%m-%d")\n        # Create timezone-aware datetime at start of day in user's timezone\n        local_start_of_day = naive_date.replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=user_tz)\n        # Convert to UTC for database query\n        target_date = local_start_of_day.astimezone(ZoneInfo("UTC")).replace(tzinfo=None)\n\n        message = await db.find_message_by_date_with_joins(chat_id, target_date)\n\n        if not message:\n            raise HTTPException(status_code=404, detail="No messages found for this date")\n\n        return message\n    except ValueError:\n        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD")\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f"Error finding message by date: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n@app.get("/api/chats/{chat_id}/export")\nasync def export_chat(chat_id: int, user: UserContext = Depends(require_auth)):\n    \"\"\"Export chat history to JSON.\"\"\"\n    user_chat_ids = get_user_chat_ids(user)\n    if user_chat_ids is not None and chat_id not in user_chat_ids:\n        raise HTTPException(status_code=403, detail="Access denied")\n\n    try:\n        chat = await db.get_chat_by_id(chat_id)\n        if not chat:\n            raise HTTPException(status_code=404, detail="Chat not found")\n\n        chat_name = chat.get("title") or chat.get("username") or str(chat_id)\n        # Sanitize filename\n        safe_name = "".join(c for c in chat_name if c.isalnum() or c in (" ", "-", "_")).strip()\n        filename = f"{safe_name}_export.json"\n\n        async def iter_json():\n            yield "[\n"\n            first = True\n            async for msg in db.get_messages_for_export(chat_id):\n                if not first:\n                    yield ",\n"\n                first = False\n                # Ensure UTF-8 encoding for non-Latin characters\n                yield json.dumps(msg, ensure_ascii=False)\n            yield "\n]"\n\n        # RFC 5987 encoding for non-ASCII filenames\n        encoded_filename = quote(filename)\n        return StreamingResponse(\n            iter_json(),\n            media_type="application/json; charset=utf-8",\n            headers={"Content-Disposition": f"attachment; filename*=UTF-8''{encoded_filename}"},\n        )\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f"Error exporting chat: {e}", exc_info=True)\n        raise HTTPException(status_code=500, detail="Internal server error")\n\n\n# ============================================================================\n# Admin Endpoints (v7.0.0) \u2014 Master-only viewer account management\n# ============================================================================\n\n\n@app.get("/api/admin/viewers")\nasync def list_viewers(user: UserContext = Depends(require_master)):\n    \"\"\"List all viewer accounts.\"\"\"\n    viewers = await db.get_all_viewer_accounts()\n    safe = []\n    for v in viewers:\n        safe.append(\n            {\n                "id": v["id"],\n                "username": v["username"],\n                "allowed_chat_ids": json.loads(v["allowed_chat_ids"]) if v["allowed_chat_ids"] else None,\n                "is_active": v["is_active"],\n                "created_by": v["created_by"],\n                "created_at": v["created_at"],\n                "updated_at": v["updated_at"],\n            }\n        )\n    return {"viewers": safe}\n\n\n@app.post("/api/admin/viewers")\nasync def create_viewer(request: Request, user: UserContext = Depends(require_master)):\n    \"\"\"Create a new viewer account.\"\"\"\n    try:\n        data = await request.json()\n    except Exception:\n        raise HTTPException(status_code=400, detail="Invalid JSON")\n\n    username = data.get("username", "").strip()\n    password = data.get("password", "").strip()\n    allowed_chat_ids = data.get("allowed_chat_ids")\n\n    if not username or len(username) < 3:\n        raise HTTPException(status_code=400, detail="Username must be at least 3 characters")\n    if not password or len(password) < 8:\n        raise HTTPException(status_code=400, detail="Password must be at least 8 characters")\n    if AUTH_ENABLED and VIEWER_USERNAME and username.lower() == VIEWER_USERNAME.lower():\n        raise HTTPException(status_code=409, detail="Username conflicts with master account")\n\n    existing = await db.get_viewer_by_username(username)\n    if existing:\n        raise HTTPException(status_code=409, detail="Username already exists")\n\n    salt = secrets.token_hex(32)\n    password_hash = _hash_password(password, salt)\n\n    chat_ids_json = None\n    if allowed_chat_ids is not None:\n        try:\n            chat_ids_json = json.dumps([int(cid) for cid in allowed_chat_ids])\n        except (ValueError, TypeError):\n            raise HTTPException(status_code=400, detail="Invalid chat ID format")\n\n    account = await db.create_viewer_account(\n        username=username,\n        password_hash=password_hash,\n        salt=salt,\n        allowed_chat_ids=chat_ids_json,\n        created_by=user.username,\n    )\n\n    await db.create_audit_log(\n        username=user.username,\n        role="master",\n        action="viewer_created",\n        endpoint="/api/admin/viewers",\n        ip_address=request.client.host if request.client else None,\n    )\n\n    return {\n        "id": account["id"],\n        "username": account["username"],\n        "allowed_chat_ids": json.loads(chat_ids_json) if chat_ids_json else None,\n        "is_active": account["is_active"],\n    }\n\n\n@app.put("/api/admin/viewers/{viewer_id}")\nasync def update_viewer(viewer_id: int, request: Request, user: UserContext = Depends(require_master)):\n    \"\"\"Update a viewer account. Invalidates their existing sessions.\"\"\"\n    try:\n        data = await request.json()\n    except Exception:\n        raise HTTPException(status_code=400, detail="Invalid JSON")\n\n    existing = await db.get_viewer_account(viewer_id)\n    if not existing:\n        raise HTTPException(status_code=404, detail="Viewer not found")\n\n    updates = {}\n    if "password" in data and data["password"]:\n        pwd = data["password"].strip()\n        if len(pwd) < 8:\n            raise HTTPException(status_code=400, detail="Password must be at least 8 characters")\n        salt = secrets.token_hex(32)\n        updates["password_hash"] = _hash_password(pwd, salt)\n        updates["salt"] = salt\n\n    if "allowed_chat_ids" in data:\n        allowed = data["allowed_chat_ids"]\n        if allowed is None:\n            updates["allowed_chat_ids"] = None\n        else:\n            try:\n                updates["allowed_chat_ids"] = json.dumps([int(cid) for cid in allowed])\n            except (ValueError, TypeError):\n                raise HTTPException(status_code=400, detail="Invalid chat ID format")\n\n    if "is_active" in data:\n        updates["is_active"] = 1 if data["is_active"] else 0\n\n    if not updates:\n        raise HTTPException(status_code=400, detail="No fields to update")\n\n    account = await db.update_viewer_account(viewer_id, **updates)\n    _invalidate_user_sessions(existing["username"])\n\n    await db.create_audit_log(\n        username=user.username,\n        role="master",\n        action=f"viewer_updated:{existing['username']}",\n        endpoint=f"/api/admin/viewers/{viewer_id}",\n        ip_address=request.client.host if request.client else None,\n    )\n\n    return {\n        "id": account["id"],\n        "username": account["username"],\n        "allowed_chat_ids": json.loads(account["allowed_chat_ids"]) if account["allowed_chat_ids"] else None,\n        "is_active": account["is_active"],\n    }\n\n\n@app.delete("/api/admin/viewers/{viewer_id}")\nasync def delete_viewer(viewer_id: int, request: Request, user: UserContext = Depends(require_master)):\n    \"\"\"Delete a viewer account and invalidate their sessions.\"\"\"\n    existing = await db.get_viewer_account(viewer_id)\n    if not existing:\n        raise HTTPException(status_code=404, detail="Viewer not found")\n\n    _invalidate_user_sessions(existing["username"])\n    await db.delete_viewer_account(viewer_id)\n\n    await db.create_audit_log(\n        username=user.username,\n        role="master",\n        action=f"viewer_deleted:{existing['username']}",\n        endpoint=f"/api/admin/viewers/{viewer_id}",\n        ip_address=request.client.host if request.client else None,\n    )\n\n    return {"success": True}\n\n\n@app.get("/api/admin/chats")\nasync def admin_list_chats(user: UserContext = Depends(require_master)):\n    \"\"\"List all chats for the admin chat picker.\"\"\"\n    chats = await db.get_all_chats()\n    return {"chats": [{"id": c["id"], "title": c.get("title"), "type": c.get("type")} for c in chats]}\n\n\n@app.get("/api/admin/audit")\nasync def get_audit_log(\n    limit: int = Query(100, ge=1, le=500),\n    offset: int = Query(0, ge=0),\n    username: str | None = Query(None),\n    user: UserContext = Depends(require_master),\n):\n    \"\"\"Get paginated audit log entries.\"\"\"\n    logs = await db.get_audit_logs(limit=limit, offset=offset, username=username)\n    return {"logs": logs, "limit": limit, "offset": offset}\n\n\n# ============================================================================\n# Real-time WebSocket Endpoints (v5.0)\n# ============================================================================\n\n\n@app.get("/api/notifications/settings")\nasync def get_notification_settings(auth_cookie: str | None = Cookie(default=None, alias=AUTH_COOKIE_NAME)):\n    \"\"\"Get notification settings for the viewer.\"\"\"\n    if AUTH_ENABLED:\n        session = _sessions.get(auth_cookie) if auth_cookie else None\n        if not session or time.time() - session.created_at > AUTH_SESSION_SECONDS:\n            return {"enabled": False, "reason": "Not authenticated"}\n\n    # Notifications enabled if:\n    # - ENABLE_NOTIFICATIONS=true (legacy), OR\n    # - PUSH_NOTIFICATIONS is 'basic' or 'full'\n    notifications_active = config.enable_notifications or config.push_notifications in ("basic", "full")\n\n    return {\n        "enabled": notifications_active,\n        "mode": config.push_notifications,  # off, basic, full\n        "websocket_url": "/ws/updates",\n    }\n\n\n@app.websocket("/ws/updates")\nasync def websocket_endpoint(websocket: WebSocket):\n    \"\"\"\n    WebSocket endpoint for real-time updates.\n\n    Auth is enforced via cookie sent during WebSocket upgrade.\n    Per-user chat filtering is applied to subscriptions.\n    \"\"\"\n    # Validate auth from cookie before accepting\n    cookies = websocket.cookies\n    auth_cookie = cookies.get(AUTH_COOKIE_NAME)\n    ws_user_chat_ids: set[int] | None = None\n\n    if AUTH_ENABLED:\n        if not auth_cookie:\n            await websocket.close(code=4001, reason="Unauthorized")\n            return\n        session = _sessions.get(auth_cookie)\n        if not session or time.time() - session.created_at > AUTH_SESSION_SECONDS:\n            await websocket.close(code=4001, reason="Session expired")\n            return\n        user_ctx = UserContext(session.username, session.role, session.allowed_chat_ids)\n        ws_user_chat_ids = get_user_chat_ids(user_ctx)\n\n    await ws_manager.connect(websocket, allowed_chat_ids=ws_user_chat_ids)\n\n    try:\n        while True:\n            data = await websocket.receive_json()\n            action = data.get("action")\n\n            if action == "subscribe":\n                chat_id = data.get("chat_id")\n                if chat_id:\n                    ws_manager.subscribe(websocket, chat_id)\n                    await websocket.send_json({"type": "subscribed", "chat_id": chat_id})\n\n            elif action == "unsubscribe":\n                chat_id = data.get("chat_id")\n                if chat_id:\n                    ws_manager.unsubscribe(websocket, chat_id)\n                    await websocket.send_json({"type": "unsubscribed", "chat_id": chat_id})\n\n            elif action == "ping":\n                await websocket.send_json({"type": "pong"})\n\n    except WebSocketDisconnect:\n        ws_manager.disconnect(websocket)\n    except Exception as e:\n        logger.error(f"WebSocket error: {e}")\n        ws_manager.disconnect(websocket)\n\n\n# ============================================================================\n# Helper functions for broadcasting updates (called from listener)\n# ============================================================================\n\n\nasync def broadcast_new_message(chat_id: int, message: dict):\n    \"\"\"Broadcast a new message to subscribed clients.\"\"\"\n    await ws_manager.broadcast_to_chat(chat_id, {"type": "new_message", "chat_id": chat_id, "message": message})\n\n\nasync def broadcast_message_edit(chat_id: int, message_id: int, new_text: str, edit_date: str):\n    \"\"\"Broadcast a message edit to subscribed clients.\"\"\"\n    await ws_manager.broadcast_to_chat(\n        chat_id,\n        {"type": "edit", "chat_id": chat_id, "message_id": message_id, "new_text": new_text, "edit_date": edit_date},\n    )\n\n\nasync def broadcast_message_delete(chat_id: int, message_id: int):\n    \"\"\"Broadcast a message deletion to subscribed clients.\"\"\"\n    await ws_manager.broadcast_to_chat(chat_id, {"type": "delete", "chat_id": chat_id, "message_id": message_id})\n